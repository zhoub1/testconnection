import re
from aws_cdk import (
    Duration, Aws, Stack, RemovalPolicy, CfnOutput, CfnDeletionPolicy,
    aws_iam as iam,
    aws_s3 as s3,
    aws_lambda as _lambda,
    aws_s3_notifications as s3_notifications,
    aws_glue as glue,
    aws_lakeformation as lakeformation,
    aws_datazone as datazone,
    Tags
)
from constructs import Construct
import json

# We import these for the custom wait resource
from aws_cdk.custom_resources import (
    AwsCustomResource,
    AwsCustomResourcePolicy,
    AwsSdkCall,
    PhysicalResourceId
)

class CdkDatazoneStack(Stack):
    r"""               
    Authors: Bill Zhou & Justin Miles
    Project: Leidos | AWS SCA (ConnectiV)

    CDK Stack to provision AWS DataZone Domain, Project, and Environment along with necessary resources.

    This stack provisions the following resources:
    - AWS DataZone Domain, Project, and Environment
    - S3 buckets for data storage
    - A Glue Crawler for processing data
    - IAM roles with necessary permissions
    - Lake Formation permissions
    - Custom resources to wait for the public and subscriber Glue databases to exist
    """

    def __init__(self, scope: Construct, construct_id: str, **kwargs) -> None:
        super().__init__(scope, construct_id, **kwargs)
        
        r"""
        We pull in context from cdk.json. The relevant fields are:
        * domain_name, domain_description
        * project_name, environment_name, environment_profile_name
        * glue_crawler_schedule, data_source_schedule
        * project_owner_identifier (an IAM ARN or SSO user ID)
        """
        # 1. Retrieve context parameters
        domain_name = self.node.try_get_context("domain_name") or "datazonedomaincdk"
        domain_description = self.node.try_get_context("domain_description") or "Description of the DataZone domain (generated by CDK)"
        project_name = self.node.try_get_context("project_name") or "datazoneproj"
        environment_name = self.node.try_get_context("environment_name") or "datazoneenv"
        environment_profile_name = self.node.try_get_context("environment_profile_name") or "env_profile"
        glue_crawler_schedule = self.node.try_get_context("glue_crawler_schedule") or "cron(0 8 * * ? *)"
        data_source_schedule = self.node.try_get_context("data_source_schedule") or "cron(0 9 * * ? *)"
        project_owner_identifier = self.node.try_get_context("project_owner_identifier")
        if not project_owner_identifier:
            raise ValueError("Context variable 'project_owner_identifier' is required and must be a valid IAM ARN or SSO identifier.")

        # 2. Validate & sanitize parameters
        def validate_parameters():
            errors = []
            if not re.match(r'^[A-Za-z0-9]+$', domain_name):
                errors.append(f"Invalid domain name '{domain_name}'. Must be alphanumeric, no spaces.")
            if not re.match(r'^[a-z0-9]+$', project_name):
                errors.append(f"Invalid project name '{project_name}'. Must be lowercase letters/numbers, no spaces.")
            if not re.match(r'^[a-z]+$', environment_name):
                errors.append(f"Invalid environment name '{environment_name}'. Must be all lowercase letters, no spaces.")
            if not re.match(r'^[A-Za-z0-9_-]+$', environment_profile_name):
                errors.append(f"Invalid environment profile name '{environment_profile_name}'. Letters, numbers, underscores, hyphens only.")
            cron_pattern = r'^cron\(.+\)$'
            if not re.match(cron_pattern, glue_crawler_schedule):
                errors.append(f"Invalid Glue Crawler schedule '{glue_crawler_schedule}'. Must be cron(...) format.")
            if not re.match(cron_pattern, data_source_schedule):
                errors.append(f"Invalid Data Source schedule '{data_source_schedule}'. Must be cron(...) format.")
            if errors:
                raise ValueError("Parameter validation failed:\n" + "\n".join(errors))

        validate_parameters()

        def sanitize_name(name, pattern, max_length, allowed_chars, name_type, desc):
            if not re.match(pattern, name):
                raise ValueError(f"Invalid {name_type} '{name}'. {desc}")
            sanitized = ''.join(c if c in allowed_chars else '-' for c in name)
            return sanitized[:max_length]

        def sanitize_bucket_name(name):
            name = name.lower()
            name = re.sub(r'[^a-z0-9-]', '-', name)
            name = re.sub(r'^-+', '', name)
            name = re.sub(r'-+$', '', name)
            if not (3 <= len(name) <= 63):
                raise ValueError(f"S3 bucket name '{name}' must be 3-63 chars.")
            return name

        domain_name = sanitize_name(
            domain_name,
            r'^[A-Za-z0-9]+$',
            64,
            'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789',
            'domain name',
            'Alphanumeric only.'
        )
        project_name = sanitize_name(
            project_name,
            r'^[a-z0-9]+$',
            64,
            'abcdefghijklmnopqrstuvwxyz0123456789',
            'project name',
            'Lowercase letters/numbers only.'
        )
        environment_name = sanitize_name(
            environment_name,
            r'^[a-z]+$',
            64,
            'abcdefghijklmnopqrstuvwxyz',
            'environment name',
            'All lowercase letters only.'
        )
        environment_profile_name = sanitize_name(
            environment_profile_name,
            r'^[A-Za-z0-9_-]+$',
            64,
            'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789_-',
            'environment profile name',
            'Letters, numbers, underscores, hyphens only.'
        )

        # 3. Create S3 buckets for data source and system store
        s3_data_source_bucket_name = sanitize_bucket_name(f"datazone-src-{self.account}-{project_name}-{self.region}")
        s3_data_source = s3.Bucket(
            self,
            "S3DataSource",
            bucket_name=s3_data_source_bucket_name,
            encryption=s3.BucketEncryption.S3_MANAGED,
            versioned=True,
            removal_policy=RemovalPolicy.DESTROY,
            auto_delete_objects=True
        )
        Tags.of(s3_data_source).add("Project", project_name)
        Tags.of(s3_data_source).add("Environment", environment_name)

        s3_datazone_sys_bucket_name = sanitize_bucket_name(f"dzsysstore-{self.account}-{project_name}-{self.region}")
        s3_datazone_sys = s3.Bucket(
            self,
            "S3DataZoneSysStore",
            bucket_name=s3_datazone_sys_bucket_name,
            encryption=s3.BucketEncryption.S3_MANAGED,
            removal_policy=RemovalPolicy.DESTROY,
            auto_delete_objects=True
        )
        Tags.of(s3_datazone_sys).add("Project", project_name)
        Tags.of(s3_datazone_sys).add("Environment", environment_name)

        # 4. IAM Role for Lambda that triggers the Glue crawler
        lambda_role_name = f"LambdaExecRole-{project_name}-{environment_name}"[:64]
        lambda_exec_role = iam.Role(
            self,
            "LambdaExecutionRole",
            role_name=lambda_role_name,
            assumed_by=iam.ServicePrincipal("lambda.amazonaws.com")
        )
        lambda_exec_role.add_to_policy(iam.PolicyStatement(
            actions=["glue:StartCrawler"],
            resources=[
                self.format_arn(
                    service="glue",
                    resource="crawler",
                    resource_name=f"{project_name}_{environment_name}_pub_db_crawler"
                )
            ]
        ))
        lambda_exec_role.add_to_policy(iam.PolicyStatement(
            actions=["logs:CreateLogGroup","logs:CreateLogStream","logs:PutLogEvents"],
            resources=[f"arn:aws:logs:{self.region}:{self.account}:log-group:/aws/lambda/*"]
        ))

        # 5. The Lambda function
        crawler_name = f"{project_name}_{environment_name}_pub_db_crawler"
        lambda_function_name = f"GlueCrawlerTriggerFunction-{project_name}-{environment_name}"[:64]
        glue_crawler_function = _lambda.Function(
            self,
            "GlueCrawlerTriggerFunction",
            function_name=lambda_function_name,
            runtime=_lambda.Runtime.NODEJS_16_X,
            handler="index.handler",
            code=_lambda.Code.from_inline("""
                const AWS = require('aws-sdk');
                const glue = new AWS.Glue();

                exports.handler = async (event) => {
                    console.log(JSON.stringify({
                        level: 'INFO',
                        message: 'Received S3 event',
                        event: event
                    }));

                    const crawlerName = process.env.CRAWLER_NAME;
                    const params = { Name: crawlerName };

                    try {
                        const data = await glue.startCrawler(params).promise();
                        console.log(JSON.stringify({
                            level: 'INFO',
                            message: `Glue crawler '${crawlerName}' started successfully.`,
                            data: data
                        }));
                    } catch (err) {
                        console.error(JSON.stringify({
                            level: 'ERROR',
                            message: `Failed to start Glue crawler '${crawlerName}'.`,
                            error: err.message,
                            stack: err.stack
                        }));
                        throw err;
                    }
                };
            """),
            environment={"CRAWLER_NAME": crawler_name},
            timeout=Duration.seconds(60),
            role=lambda_exec_role
        )
        glue_crawler_function.add_permission(
            "LambdaInvokePermission",
            principal=iam.ServicePrincipal("s3.amazonaws.com"),
            action="lambda:InvokeFunction",
            source_arn=s3_data_source.bucket_arn
        )
        s3_data_source.add_event_notification(
            s3.EventType.OBJECT_CREATED,
            s3_notifications.LambdaDestination(glue_crawler_function)
        )

        # 6. Domain Execution Role
        domain_role_name = f"DZDomainRole-{self.account}-{self.stack_name}"[:64]
        domain_exec_role = iam.Role(
            self,
            "DataZoneDomainExecutionRole",
            role_name=domain_role_name,
            assumed_by=iam.ServicePrincipal("datazone.amazonaws.com")
        )
        domain_exec_role.assume_role_policy.add_statements(
            iam.PolicyStatement(
                effect=iam.Effect.ALLOW,
                actions=["sts:AssumeRole","sts:TagSession"],
                principals=[
                    iam.ServicePrincipal("datazone.amazonaws.com"),
                    iam.ServicePrincipal("lakeformation.amazonaws.com")
                ],
                conditions={
                    "StringEquals": {"aws:SourceAccount": Aws.ACCOUNT_ID},
                    "ForAllValues:StringLike": {"aws:TagKeys": "datazone*"}
                }
            )
        )
        # Attach some managed policies
        domain_exec_role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name("AmazonAthenaFullAccess"))
        domain_exec_role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name("service-role/AmazonDataZoneDomainExecutionRolePolicy"))
        domain_exec_role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name("AmazonDataZoneRedshiftGlueProvisioningPolicy"))
        # Lake Formation perms
        domain_exec_role.add_to_policy(iam.PolicyStatement(
            actions=[
                "lakeformation:GrantPermissions","lakeformation:RevokePermissions","lakeformation:GetDataAccess",
                "lakeformation:GetEffectivePermissionsForPath","lakeformation:ListPermissions","lakeformation:GetResourceLFTags",
                "lakeformation:PutDataLakeSettings","lakeformation:DescribeResource","lakeformation:RegisterResource",
                "lakeformation:DeregisterResource","lakeformation:ListResources","lakeformation:AddLFTagsToResource",
                "lakeformation:RemoveLFTagsFromResource","lakeformation:SearchTablesByLFTags","lakeformation:GetLFTag",
                "lakeformation:CreateLFTag","lakeformation:DeleteLFTag","lakeformation:ListLFTags","lakeformation:TagResource",
                "lakeformation:UntagResource","lakeformation:GetDataLakeSettings"
            ],
            resources=["*"]
        ))
        domain_exec_role.add_to_policy(iam.PolicyStatement(
            actions=["iam:GetRole","iam:GetUser"],
            resources=["*"]
        ))
        domain_exec_role.add_to_policy(iam.PolicyStatement(
            actions=["glue:GetDatabase","glue:GetTable"],
            resources=["*"]
        ))
        domain_exec_role.add_to_policy(iam.PolicyStatement(
            actions=["logs:CreateLogGroup","logs:CreateLogStream","logs:PutLogEvents"],
            resources=[f"arn:aws:logs:{self.region}:{self.account}:log-group:/aws/lambda/*"]
        ))
        domain_exec_role.add_to_policy(iam.PolicyStatement(
            actions=["s3:GetObject","s3:PutObject","s3:DeleteObject","s3:ListBucket","s3:PutBucketPolicy","s3:GetBucketPolicy"],
            resources=[
                s3_data_source.bucket_arn, f"{s3_data_source.bucket_arn}/*",
                s3_datazone_sys.bucket_arn, f"{s3_datazone_sys.bucket_arn}/*"
            ]
        ))
        Tags.of(domain_exec_role).add("Project", project_name)
        Tags.of(domain_exec_role).add("Environment", environment_name)

        # 7. Lake Formation Data Lake Administrator settings
        data_lake_settings = lakeformation.CfnDataLakeSettings(
            self,
            "DataLakeAdministrator",
            admins=[lakeformation.CfnDataLakeSettings.DataLakePrincipalProperty(
                data_lake_principal_identifier=domain_exec_role.role_arn
            )],
            trusted_resource_owners=[domain_exec_role.role_arn]
        )
        data_lake_settings.node.add_dependency(domain_exec_role)

        # 8. Amazon DataZone Domain
        datazone_domain = datazone.CfnDomain(
            self,
            "DataZoneDomain",
            name=domain_name,
            description=domain_description,
            domain_execution_role=domain_exec_role.role_arn
        )
        datazone_domain.node.add_dependency(domain_exec_role)

        # 9. DataZone Project
        datazone_project = datazone.CfnProject(
            self,
            "DataZoneProject",
            name=project_name,
            description=domain_description,
            domain_identifier=datazone_domain.attr_id
        )
        datazone_project.node.add_dependency(datazone_domain)

        # 10. DataZone Project Membership (owner)
        datazone_project_membership = datazone.CfnProjectMembership(
            self,
            "DataZoneProjectMembership",
            domain_identifier=datazone_domain.attr_id,
            project_identifier=datazone_project.attr_id,
            designation='PROJECT_OWNER',
            member=datazone.CfnProjectMembership.MemberProperty(
                user_identifier=project_owner_identifier
            )
        )
        datazone_project_membership.node.add_dependency(datazone_project)

        # 11. Environment Blueprint configuration
        datazone_env_blueprint = datazone.CfnEnvironmentBlueprintConfiguration(
            self,
            "DataZoneEnvBlueprint",
            domain_identifier=datazone_domain.attr_id,
            environment_blueprint_identifier="DefaultDataLake",
            manage_access_role_arn=domain_exec_role.role_arn,
            provisioning_role_arn=domain_exec_role.role_arn,
            regional_parameters=[
                datazone.CfnEnvironmentBlueprintConfiguration.RegionalParameterProperty(
                    region=self.region,
                    parameters={"S3Location": f"s3://{s3_datazone_sys.bucket_name}"}
                )
            ],
            enabled_regions=[self.region]
        )
        datazone_env_blueprint.node.add_dependency(datazone_domain)

        # 12. Environment Profile
        datazone_env_profile = datazone.CfnEnvironmentProfile(
            self,
            "DataZoneEnvProfile",
            name=environment_profile_name,
            project_identifier=datazone_project.attr_id,
            aws_account_id=self.account,
            aws_account_region=self.region,
            description=domain_description,
            domain_identifier=datazone_domain.attr_id,
            environment_blueprint_identifier=datazone_env_blueprint.attr_environment_blueprint_id
        )
        datazone_env_profile.node.add_dependency(datazone_env_blueprint)

        # 13. Environment creation
        datazone_environment = datazone.CfnEnvironment(
            self,
            "DataZoneEnvironment",
            name=environment_name,
            domain_identifier=datazone_domain.attr_id,
            environment_profile_identifier=datazone_env_profile.attr_id,
            project_identifier=datazone_project.attr_id
        )
        datazone_environment.node.add_dependency(datazone_env_profile)
        datazone_environment.cfn_options.deletion_policy = CfnDeletionPolicy.DELETE

        # 14. Data Source configuration
        datazone_data_source = datazone.CfnDataSource(
            self,
            "DataZoneDataSource",
            domain_identifier=datazone_domain.attr_id,
            environment_identifier=datazone_environment.attr_id,
            project_identifier=datazone_project.attr_id,
            name="PrimaryDataMeshDataSource",
            description="Data source for DataZone (Generated by CDK)",
            type="GLUE",
            configuration=datazone.CfnDataSource.DataSourceConfigurationInputProperty(
                glue_run_configuration=datazone.CfnDataSource.GlueRunConfigurationInputProperty(
                    relational_filter_configurations=[
                        datazone.CfnDataSource.RelationalFilterConfigurationProperty(
                            database_name=f"{environment_name}_pub_db"
                        )
                    ]
                )
            ),
            enable_setting="ENABLED",
            recommendation=datazone.CfnDataSource.RecommendationConfigurationProperty(
                enable_business_name_generation=True
            ),
            schedule=datazone.CfnDataSource.ScheduleConfigurationProperty(
                schedule=data_source_schedule,
                timezone="UTC"
            )
        )
        datazone_data_source.cfn_options.deletion_policy = CfnDeletionPolicy.DELETE
        datazone_data_source.add_dependency(datazone_environment)

        # 15. Register S3 data source location in Lake Formation
        register_s3_location = lakeformation.CfnResource(
            self,
            "RegisterS3Location",
            resource_arn=s3_data_source.bucket_arn,
            use_service_linked_role=True  # <--- use the built-in Lake Formation service-linked role
        )

        register_s3_location.node.add_dependency(datazone_environment)

        # 16. Glue Crawler Role
        crawler_role_name = f"GlueCrawlerRole-{project_name}-{environment_name}"[:64]
        crawler_role = iam.Role(
            self,
            "GlueCrawlerRole",
            role_name=crawler_role_name,
            assumed_by=iam.ServicePrincipal("glue.amazonaws.com")
        )
        crawler_role.add_managed_policy(iam.ManagedPolicy.from_aws_managed_policy_name("service-role/AWSGlueServiceRole"))
        crawler_role.add_to_policy(iam.PolicyStatement(
            actions=["s3:GetObject","s3:PutObject","s3:DeleteObject","s3:ListBucket"],
            resources=[s3_data_source.bucket_arn, f"{s3_data_source.bucket_arn}/*"]
        ))
        crawler_role.add_to_policy(iam.PolicyStatement(
            actions=["glue:GetDatabase","glue:GetTables","glue:CreateTable","glue:UpdateTable"],
            resources=[
                self.format_arn(
                    service="glue",
                    resource="database",
                    resource_name=f"{environment_name}_pub_db"
                ),
                self.format_arn(
                    service="glue",
                    resource="table",
                    resource_name=f"{environment_name}_pub_db/*"
                )
            ]
        ))
        crawler_role.add_to_policy(iam.PolicyStatement(
            actions=["lakeformation:GetDataAccess"],
            resources=["*"]
        ))
        crawler_role.add_to_policy(iam.PolicyStatement(
            actions=["logs:CreateLogGroup","logs:CreateLogStream","logs:PutLogEvents"],
            resources=[f"arn:aws:logs:{self.region}:{self.account}:log-group:/aws-glue/*"]
        ))
        Tags.of(crawler_role).add("Project", project_name)
        Tags.of(crawler_role).add("Environment", environment_name)

        # 17. Lake Formation perms for crawler on the S3 location
        lakeformation_permissions_crawler_s3 = lakeformation.CfnPermissions(
            self,
            "LakeFormationPermissionsCrawlerS3",
            data_lake_principal=lakeformation.CfnPermissions.DataLakePrincipalProperty(
                data_lake_principal_identifier=crawler_role.role_arn
            ),
            resource=lakeformation.CfnPermissions.ResourceProperty(
                data_location_resource=lakeformation.CfnPermissions.DataLocationResourceProperty(
                    s3_resource=s3_data_source.bucket_arn
                )
            ),
            permissions=["DATA_LOCATION_ACCESS"],
            permissions_with_grant_option=[]
        )
        lakeformation_permissions_crawler_s3.node.add_dependency(register_s3_location)

        # 18. Lake Formation perms for crawler on the public DB
        lakeformation_permissions_crawler_db = lakeformation.CfnPermissions(
            self,
            "LakeFormationPermissionsCrawlerDB",
            data_lake_principal=lakeformation.CfnPermissions.DataLakePrincipalProperty(
                data_lake_principal_identifier=crawler_role.role_arn
            ),
            resource=lakeformation.CfnPermissions.ResourceProperty(
                database_resource=lakeformation.CfnPermissions.DatabaseResourceProperty(
                    name=f"{environment_name}_pub_db"
                )
            ),
            permissions=["ALL"],
            permissions_with_grant_option=[]
        )
        lakeformation_permissions_crawler_db.node.add_dependency(datazone_environment)

        # 19. The Glue Crawler
        crawler_configuration = json.dumps({
            "Version": 1.0,
            "CrawlerOutput": {
                "Partitions": {
                    "AddOrUpdateBehavior": "InheritFromTable"
                }
            }
        })
        glue_crawler = glue.CfnCrawler(
            self,
            "GlueCrawler",
            name=crawler_name,
            role=crawler_role.role_arn,
            database_name=f"{environment_name}_pub_db",
            targets=glue.CfnCrawler.TargetsProperty(
                s3_targets=[glue.CfnCrawler.S3TargetProperty(
                    path=f"s3://{s3_data_source.bucket_name}/"
                )]
            ),
            table_prefix=f"{environment_name}_pub_",
            schema_change_policy=glue.CfnCrawler.SchemaChangePolicyProperty(
                update_behavior="UPDATE_IN_DATABASE",
                delete_behavior="LOG"
            ),
            configuration=crawler_configuration,
            schedule=glue.CfnCrawler.ScheduleProperty(
                schedule_expression=glue_crawler_schedule
            )
        )
        glue_crawler.node.add_dependency(register_s3_location)
        glue_crawler.node.add_dependency(crawler_role)
        glue_crawler.node.add_dependency(lakeformation_permissions_crawler_s3)
        glue_crawler.node.add_dependency(lakeformation_permissions_crawler_db)

        # 20. Lake Formation perms for domain exec role on the pub DB
        lakeformation_permissions_role_pub = lakeformation.CfnPermissions(
            self,
            "LakeFormationPermissionsRolePub",
            data_lake_principal=lakeformation.CfnPermissions.DataLakePrincipalProperty(
                data_lake_principal_identifier=domain_exec_role.role_arn
            ),
            resource=lakeformation.CfnPermissions.ResourceProperty(
                database_resource=lakeformation.CfnPermissions.DatabaseResourceProperty(
                    name=f"{environment_name}_pub_db"
                )
            ),
            permissions=["ALL"],
            permissions_with_grant_option=["ALL"]
        )
        lakeformation_permissions_role_pub.node.add_dependency(datazone_environment)

        # 21. Lake Formation perms for domain exec role on the sub DB
        lakeformation_permissions_role_sub = lakeformation.CfnPermissions(
            self,
            "LakeFormationPermissionsRoleSub",
            data_lake_principal=lakeformation.CfnPermissions.DataLakePrincipalProperty(
                data_lake_principal_identifier=domain_exec_role.role_arn
            ),
            resource=lakeformation.CfnPermissions.ResourceProperty(
                database_resource=lakeformation.CfnPermissions.DatabaseResourceProperty(
                    name=f"{environment_name}_sub_db"
                )
            ),
            permissions=["ALL"],
            permissions_with_grant_option=["ALL"]
        )
        lakeformation_permissions_role_sub.node.add_dependency(datazone_environment)

        #
        # 22. Wait for the pub DB (environment_name_pub_db) to exist
        #
        wait_for_pub_db = AwsCustomResource(
            self,
            "WaitForPubDB",
            policy=AwsCustomResourcePolicy.from_statements([
                iam.PolicyStatement(
                    actions=["glue:GetDatabase"],
                    resources=["*"]  # needed to call getDatabase
                )
            ]),
            on_create=AwsSdkCall(
                service="Glue",
                action="getDatabase",
                parameters={"Name": f"{environment_name}_pub_db"},
                physical_resource_id=PhysicalResourceId.of(f"{environment_name}_pub_db-wait"),
                ignore_error_codes_matching="EntityNotFoundException"
            ),
            on_update=AwsSdkCall(
                service="Glue",
                action="getDatabase",
                parameters={"Name": f"{environment_name}_pub_db"},
                physical_resource_id=PhysicalResourceId.of(f"{environment_name}_pub_db-wait"),
                ignore_error_codes_matching="EntityNotFoundException"
            ),
            timeout=Duration.minutes(2)
        )
        wait_for_pub_db.node.add_dependency(datazone_environment)

        # Make the pub DB references wait for WaitForPubDB
        lakeformation_permissions_crawler_db.node.add_dependency(wait_for_pub_db)
        glue_crawler.node.add_dependency(wait_for_pub_db)
        lakeformation_permissions_role_pub.node.add_dependency(wait_for_pub_db)

        #
        # 23. Wait for the sub DB (environment_name_sub_db) to exist
        # so LakeFormationPermissionsRoleSub doesn't fail.
        #
        wait_for_sub_db = AwsCustomResource(
            self,
            "WaitForSubDB",
            policy=AwsCustomResourcePolicy.from_statements([
                iam.PolicyStatement(
                    actions=["glue:GetDatabase"],
                    resources=["*"]
                )
            ]),
            on_create=AwsSdkCall(
                service="Glue",
                action="getDatabase",
                parameters={"Name": f"{environment_name}_sub_db"},
                physical_resource_id=PhysicalResourceId.of(f"{environment_name}_sub_db-wait"),
                ignore_error_codes_matching="EntityNotFoundException"
            ),
            on_update=AwsSdkCall(
                service="Glue",
                action="getDatabase",
                parameters={"Name": f"{environment_name}_sub_db"},
                physical_resource_id=PhysicalResourceId.of(f"{environment_name}_sub_db-wait"),
                ignore_error_codes_matching="EntityNotFoundException"
            ),
            timeout=Duration.minutes(2)
        )
        wait_for_sub_db.node.add_dependency(datazone_environment)

        # Make the sub DB references wait for WaitForSubDB
        lakeformation_permissions_role_sub.node.add_dependency(wait_for_sub_db)

        #
        # 24. Outputs
        #
        CfnOutput(self, "S3DataSourceBucketName", value=s3_data_source.bucket_name)
        CfnOutput(self, "S3DataZoneSysStoreBucketName", value=s3_datazone_sys.bucket_name)
        CfnOutput(self, "GlueCrawlerName", value=glue_crawler.name)
        CfnOutput(self, "GlueTablePrefix", value=f"{environment_name}_pub_")
        CfnOutput(self, "DataZoneDomainPortalUrl", value=datazone_domain.attr_portal_url)
        CfnOutput(self, "DataZoneDomainId", value=datazone_domain.attr_id)
        CfnOutput(self, "DataZoneExecutionRoleArn", value=domain_exec_role.role_arn)
